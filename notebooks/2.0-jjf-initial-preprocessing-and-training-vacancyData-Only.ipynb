{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Training Data Development - Vacancy Rates \n",
    "### Goal:  Create a cleaned development dataset you can use to complete the modeling step of your project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps: \n",
    "● 1. Create dummy or indicator features for categorical variables\n",
    "\n",
    "● 2. Standardize the magnitude of numeric features using a scaler\n",
    "\n",
    "● 3. Split into testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "path= '/Users/josephfrasca/Coding_Stuff/Springboard/Capstone_2/data/interim'\n",
    "os.chdir(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Vacancy_Rate%</th>\n",
       "      <th>MOE-VacancyRate%</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02333</td>\n",
       "      <td>3.024027</td>\n",
       "      <td>2.199925</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02338</td>\n",
       "      <td>3.116343</td>\n",
       "      <td>2.948791</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02339</td>\n",
       "      <td>4.464646</td>\n",
       "      <td>2.066438</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02341</td>\n",
       "      <td>3.586322</td>\n",
       "      <td>2.340722</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02343</td>\n",
       "      <td>3.732901</td>\n",
       "      <td>2.926524</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264965</th>\n",
       "      <td>NATNL</td>\n",
       "      <td>6.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264966</th>\n",
       "      <td>NATNL</td>\n",
       "      <td>7.175000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264967</th>\n",
       "      <td>NATNL</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264968</th>\n",
       "      <td>NATNL</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264969</th>\n",
       "      <td>NATNL</td>\n",
       "      <td>6.230000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264970 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zipcode  Vacancy_Rate%  MOE-VacancyRate%       Year\n",
       "0        02333       3.024027          2.199925 2011-01-01\n",
       "1        02338       3.116343          2.948791 2011-01-01\n",
       "2        02339       4.464646          2.066438 2011-01-01\n",
       "3        02341       3.586322          2.340722 2011-01-01\n",
       "4        02343       3.732901          2.926524 2011-01-01\n",
       "...        ...            ...               ...        ...\n",
       "264965   NATNL       6.850000          0.000000 2016-01-01\n",
       "264966   NATNL       7.175000          0.000000 2017-01-01\n",
       "264967   NATNL       6.875000          0.000000 2018-01-01\n",
       "264968   NATNL       6.750000          0.000000 2019-01-01\n",
       "264969   NATNL       6.230000          0.000000 2020-01-01\n",
       "\n",
       "[264970 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.read_csv('VacancyRate_Zipcode_AND_National_2011_2020.csv',  dtype={'Zipcode': object}, parse_dates=['Year'])\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zipcode                     object\n",
       "Vacancy_Rate%              float64\n",
       "MOE-VacancyRate%           float64\n",
       "Year                datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Vacancy_Rate%</th>\n",
       "      <th>MOE-VacancyRate%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>02333</td>\n",
       "      <td>3.024027</td>\n",
       "      <td>2.199925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>02338</td>\n",
       "      <td>3.116343</td>\n",
       "      <td>2.948791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>02339</td>\n",
       "      <td>4.464646</td>\n",
       "      <td>2.066438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>02341</td>\n",
       "      <td>3.586322</td>\n",
       "      <td>2.340722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>02343</td>\n",
       "      <td>3.732901</td>\n",
       "      <td>2.926524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Zipcode  Vacancy_Rate%  MOE-VacancyRate%\n",
       "Year                                               \n",
       "2011-01-01   02333       3.024027          2.199925\n",
       "2011-01-01   02338       3.116343          2.948791\n",
       "2011-01-01   02339       4.464646          2.066438\n",
       "2011-01-01   02341       3.586322          2.340722\n",
       "2011-01-01   02343       3.732901          2.926524"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new dataframe, setting the index to 'Year'\n",
    "df = DF.set_index('Year')\n",
    "#Save the DATE labels \n",
    "df_index = df.index\n",
    "#Save the column names\n",
    "df_columns = df.columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zipcode             0\n",
       "Vacancy_Rate%       0\n",
       "MOE-VacancyRate%    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for NaNs\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000      5.630071\n",
       "100.000000    0.207571\n",
       "20.000000     0.046043\n",
       "33.333333     0.040759\n",
       "25.000000     0.037363\n",
       "                ...   \n",
       "8.671855      0.000377\n",
       "17.389154     0.000377\n",
       "2.754040      0.000377\n",
       "26.238062     0.000377\n",
       "5.466803      0.000377\n",
       "Name: MOE-VacancyRate%, Length: 234862, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique values for each column\n",
    "df['MOE-VacancyRate%'].value_counts()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zipcode               int64\n",
       "Vacancy_Rate%       float64\n",
       "MOE-VacancyRate%    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change National ('NATNL') zipcode to '99999' for later modeling\n",
    "df.Zipcode.replace('NATNL', '99999', inplace=True)\n",
    "df.Zipcode = df.Zipcode.astype('int')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 211976.0 test size: 52994.0\n"
     ]
    }
   ],
   "source": [
    "#check partition sizes with a 80/20 train/test split for all DataFrames\n",
    "print('train size:', len(df) * .80, 'test size:', len(df) * .20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split into testing and training datasets\n",
    "Hint: don’t forget your sklearn functions here, like train_test_split()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate 2020 data from data set for later use and prediction\n",
    "df_2019AND20 = df[df.index > '2018']\n",
    "df = df[df.index < '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define variable X, y\n",
    "X = df.drop('Vacancy_Rate%', axis=1)\n",
    "y = df['Vacancy_Rate%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split each of the 4 DFs\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Baseline Measurement Comparisons\n",
    "Using a Dummy Regressor see what R2, MSE, and MAE would be if the mean of the DataFrames were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.688364513059945\n"
     ]
    }
   ],
   "source": [
    "#initial not even a model\n",
    "train_mean = y_train.mean()\n",
    "\n",
    "print(train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -1.7221596428695918e-05)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the dummy regressor on the training data\n",
    "dumb_reg = DummyRegressor(strategy='mean')\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "#create dummy regressor predictions \n",
    "y_tr_pred = dumb_reg.predict(X_train)\n",
    "#Make prediction with the single value of the (training) mean.\n",
    "y_te_pred = train_mean * np.ones(len(y_test))\n",
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAEs: 11.766127007670223 11.703398452536309\n",
      "MSEs: 270.86710986879007 267.5387213119894\n"
     ]
    }
   ],
   "source": [
    "#establish baseline for mean absolute error and mean square error \n",
    "print('MAEs:', mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred))\n",
    "print('MSEs:', mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Create dummy or indicator features for categorical variables\n",
    "Hint: you’ll need to think about your old favorite pandas functions here like\n",
    "get_dummies() . Consult this guide for help.\n",
    "<https://towardsdatascience.com/the-dummys-guide-to-creating-dummy-variables-f21faddb1d40>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step not needed as the zipcode variable was changed to integer above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Standardize the magnitude of numeric features using a scaler\n",
    "Hint: you might need to employ Python code like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Making a Scaler object\\nscaler = preprocessing.StandardScaler()\\n# Fitting data to the scaler object\\nscaled_df = scaler.fit_transform(df)\\nscaled_df = pd.DataFrame(scaled_df, columns=names)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Making a Scaler object\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# Fitting data to the scaler object\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=names)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't need because everythin is % (0-100)\n",
    "'''\n",
    "scaler = StandardScaler()\n",
    "#fit the scaler on the training set\n",
    "scaler.fit(X_train)\n",
    "#apply the scaling to both the train and test split\n",
    "X_tr_scaled = scaler.transform(X_train)\n",
    "X_te_scaled = scaler.transform(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Model: Train the model on the train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions using the model on both train and test splits\n",
    "y_tr_pred = lm.predict(X_train)\n",
    "y_te_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: (0.48181793766528913, 0.48624846101375807)\n"
     ]
    }
   ],
   "source": [
    "#Assess model performance\n",
    "# r^2 - train, test\n",
    "r2 = r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)\n",
    "print('r2:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is markedly better performance than when using Dummy variable/mean for R^2 (see earlier):**\n",
    "\n",
    "Dummy R2 = (0.0, -1.7221596428695918e-05)\n",
    "\n",
    "**Note: It does seem as is this model may be overfitting, as the y-test performs slightly better than the y-train**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: (8.013226732182535, 7.935339791599616)\n"
     ]
    }
   ],
   "source": [
    "#MAE - train, test\n",
    "mae = mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)\n",
    "print('mae:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: (140.35847761045238, 137.44606277182206)\n"
     ]
    }
   ],
   "source": [
    "# MSE - train, test\n",
    "mse = mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)\n",
    "print('mse:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is markedly better performance than when using Dummy variable/mean for R^2 (see earlier):**\n",
    "\n",
    "Dummy -\n",
    "\n",
    "MAEs: 11.766127007670223 11.703398452536309\n",
    "\n",
    "MSEs: 270.86710986879007 267.5387213119894\n",
    "\n",
    "**MSE still very high (possibly due to this being a large data set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save vacancy rate data for modeling - remember to use random state=42!\n",
    "df.to_csv(r'/Users/josephfrasca/Coding_Stuff/Springboard/Capstone_2/data/processed/VacancyRate_Zipcode_AND_National_2011_2018', index=False)\n",
    "df_2019AND20.to_csv(r'/Users/josephfrasca/Coding_Stuff/Springboard/Capstone_2/data/processed/VacancyRate_Zipcode_National_2019_2020', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the scaled training and test splits\n",
    "\n",
    "#X_tr_scaled.to_csv(r'/Users/josephfrasca/Coding_Stuff/Springboard/Capstone_2/data/processed/X_tr_scaled', index=False)\n",
    "#X_te_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This summary should provide a quick overview for someone wanting to know quickly why the given model was chosen for the next part of the business problem to help guide important business decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection: \n",
    "**Review the following questions and apply them to your dataset**:\n",
    "\n",
    "● Does my data set have any categorical data, such as Gender or day of the week?\n",
    "\n",
    "● Do my features have data values that range from 0 - 100 or 0-1 or both and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to add in categorical varirables: city, metro, sizerank etc.\n",
    "    #need to create pd.get_dummies to handle this\n",
    "#add in other FRED/ACS data points from 2011-2018 (both zipcode and national)\n",
    "    #train model on scaled data!!! (after adding in other variables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
